{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Documents: 4798879\n"
     ]
    }
   ],
   "source": [
    "#import modules\n",
    "import os.path\n",
    "import nltk\n",
    "from gensim import corpora\n",
    "from gensim.models import LsiModel\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def getData(path,file): #functie pentru preluarea informatiei din fisier\n",
    "    documentsList = []\n",
    "    titles=[]\n",
    "    with open( os.path.join(path, file) ,\"r\") as fin:\n",
    "        for line in fin.readlines():\n",
    "            text = line.strip()\n",
    "            documentsList.append(text)\n",
    "    print(\"Numarul total de documente:\",len(documentsList))\n",
    "    titles.append( text[0:min(len(text),100)] ) #considera titlu primele 100 cuvinte\n",
    "    return documentsList,titles\n",
    "\n",
    "def prepreparingData(docList): # functie pentru a desparti in termeni textul, a sterge si se categorisesc cuvintele cu aceeasi radacina(stemming)\n",
    "    # initializare regex tokenizer\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    # se creaza lista de stop words in engleza, mai exact cuvinte de legatura sau fara relevanta in mesajul textului\n",
    "    en_stop = set(stopwords.words('english'))\n",
    "    # pentru cuvintele regasite sub diferite forme\n",
    "    p_stemmer = PorterStemmer()\n",
    "    texts = []\n",
    "    for i in docList:\n",
    "        raw = i.lower() # se aduce textul la lowercase\n",
    "        tokens = tokenizer.tokenize(raw)\n",
    "        # eliminare stop words\n",
    "        stopped_tokens = [i for i in tokens if not i in en_stop]\n",
    "        # stemming\n",
    "        stemmed_tokens = [p_stemmer.stem(i) for i in stopped_tokens]\n",
    "        texts.append(stemmed_tokens)\n",
    "    return texts\n",
    "\n",
    "def preparingDoc(prepreparedDoc): # functie cu scopul de a crea matricea termeni-documente \n",
    "    # fiecarui cuvant dintr-un document ii este atribuit un index conturandu-se astfel un dictionar\n",
    "    dictionary = corpora.Dictionary(prepreparedDoc)\n",
    "    # crearea matricei termeni documente\n",
    "    DocumentsTermsMatrix = [dictionary.doc2bow(doc) for doc in prepreparedDoc]  \n",
    "    return dictionary,DocumentsTermsMatrix\n",
    "\n",
    "def createLSAModel(document,nrTopics,words): # cream LSA utilizand gensim\n",
    "    dictionary,DocumentsTermsMatrix = preparingDoc(document)\n",
    "    #LSA \n",
    "    lsamodel = LsiModel(DocumentsTermsMatrix, num_topics = nrTopics, id2word = dictionary)  \n",
    "    print(lsamodel.print_topics(num_topics = nrTopics, num_words = words))\n",
    "    return lsamodel\n",
    "\n",
    "numberTopics = 7\n",
    "words = 10\n",
    "documentList,titles = getData(\"\",\"papers.csv\")\n",
    "prepreparedText = prepreparingData(documentList)\n",
    "model = createLSAModel(prepreparedText,numberTopics,words)\n",
    "\n",
    "def coherenceValues(dictionary, documentTermMatrix, preparedDocument, maxNrTopics, start=2, step=3):\n",
    "    coherenceValues = []\n",
    "    modelList = []\n",
    "    for nrtopics in range(start, maxNrTopics, step):\n",
    "        model = LsiModel(documentTermMatrix, nrtopics=numberTopics, id2word = dictionary)\n",
    "        modelList.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=preparedDocument, dictionary=dictionary, coherence='c_v')\n",
    "        coherenceValues.append(coherencemodel.get_coherence())\n",
    "    return modelList, coherenceValues\n",
    "def plot_graph(preparedDoc,start, stop, step):\n",
    "    dictionary,documentsTermsMatrix=preparingDoc(preparedDoc)\n",
    "    modelList, coherenceValues = coherenceValues(dictionary, documentsTermsMatrix,preparedDoc,\n",
    "                                                            stop, start, step)\n",
    "    # Show graph\n",
    "    x = range(start, stop, step)\n",
    "    plt.plot(x, coherenceValues)\n",
    "    plt.xlabel(\"Nr Topics\")\n",
    "    plt.ylabel(\"Coerenta\")\n",
    "    plt.legend((\"coherence_values\"), loc='best')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "start,stop,step=2,12,1\n",
    "plot_graph(prepreparedText,start,stop,step)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b47e9715c2a8bc0179ff3d7769d4ea0e7be5fc19acddbd1b1a9bd07f5c94e09e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
